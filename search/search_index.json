{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>fact</code> User Guide","text":"<code>python-blueprint</code> Project <p>For more information on how this was built and deployed, as well as other Python best practices, see <code>python-blueprint</code>.</p> <p>Info</p> <p>This user guide is purely an illustrative example that shows off several features of  Material for MkDocs and included Markdown extensions<sup>1</sup>.</p>"},{"location":"#installation","title":"Installation","text":"<p>First, install Poetry:</p> Linux/macOSWindows <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre> <pre><code>(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -\n</code></pre> <p>Then install the <code>fact</code> package and its dependencies:</p> <pre><code>poetry install\n</code></pre> <p>Activate the virtual environment created automatically by Poetry:</p> <pre><code>poetry shell\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>To use <code>fact</code> within your project, import the <code>factorial</code> function and execute it like:</p> <pre><code>from fact.lib import factorial\n\nassert factorial(3) == 6 # (1)!\n</code></pre> <ol> <li>This assertion will be <code>True</code></li> </ol> <p>Tip</p> <p>Within PyCharm, use Tab to auto-complete suggested imports while typing.</p>"},{"location":"#expected-results","title":"Expected Results","text":"Input Output 1 1 2 2 3 6 4 24 <ol> <li> <p>See <code>python-blueprint</code>'s <code>mkdocs.yml</code> for how to enable these features.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>lazy_search<ul> <li>cli</li> <li>models</li> <li>news_fetcher</li> <li>nlp</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/lazy_search/__init__/","title":"init","text":""},{"location":"reference/lazy_search/cli/","title":"cli","text":""},{"location":"reference/lazy_search/cli/#lazy_search.cli.api_key_typer_option","title":"<code>api_key_typer_option = typer.Option('', '--api-key', '-k', help='The api key for the news api')</code>  <code>module-attribute</code>","text":""},{"location":"reference/lazy_search/cli/#lazy_search.cli.app","title":"<code>app = Typer(add_completion=False)</code>  <code>module-attribute</code>","text":""},{"location":"reference/lazy_search/cli/#lazy_search.cli.language_typer_option","title":"<code>language_typer_option = typer.Option('en', '--language', '-l', help='The language you want to search for', callback=validate_langauge_input)</code>  <code>module-attribute</code>","text":""},{"location":"reference/lazy_search/cli/#lazy_search.cli.topic_annotation","title":"<code>topic_annotation = Annotated[list[str], Argument(min=0, help='The topic you want to search for')]</code>  <code>module-attribute</code>","text":""},{"location":"reference/lazy_search/cli/#lazy_search.cli.UnsupportedLanguageException","title":"<code>UnsupportedLanguageException</code>","text":"<p>             Bases: <code>BadParameter</code></p> Source code in <code>src/lazy_search/cli.py</code> <pre><code>class UnsupportedLanguageException(typer.BadParameter):\n    def __init__(self, language: str):\n        supported_languages = \", \".join(ArticleLanguage.__members__.values())\n        message = f\"Language '{language}' is not supported. Supported languages are: {supported_languages}\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/lazy_search/cli/#lazy_search.cli.UnsupportedLanguageException.__init__","title":"<code>__init__(language: str)</code>","text":"Source code in <code>src/lazy_search/cli.py</code> <pre><code>def __init__(self, language: str):\n    supported_languages = \", \".join(ArticleLanguage.__members__.values())\n    message = f\"Language '{language}' is not supported. Supported languages are: {supported_languages}\"\n    super().__init__(message)\n</code></pre>"},{"location":"reference/lazy_search/cli/#lazy_search.cli.main","title":"<code>main(topics: topic_annotation, language: str = language_typer_option, api_key: str = api_key_typer_option) -&gt; None</code>","text":"<p>Search the web for a given topic or multiple and generate summary as well as a report of the top 15 articles</p> Source code in <code>src/lazy_search/cli.py</code> <pre><code>@app.command()\ndef main(\n    topics: topic_annotation,\n    language: str = language_typer_option,\n    api_key: str = api_key_typer_option,\n) -&gt; None:\n\"\"\"Search the web for a given topic or multiple and generate summary as well as a report of the top 15 articles\"\"\"\n    console = Console()\n\n    nlp_loader = NlpLoader()\n    if not nlp_loader.is_language_downloaded(ArticleLanguage(language)):\n        print(\n            \"[bold orange_red1][INFO] Language not downloaded, downloading now... [/bold orange_red1]\"\n        )\n    nlp = NaturalLanguageProcessor(language=ArticleLanguage(language))\n    news_fetcher = NewsFetcher(api_key=api_key)\n\n    for topic in topics:\n        response = news_fetcher.search(topic=topic, language=ArticleLanguage(language))\n        articles = response.articles\n        table = Table(\n            title=f\"Articles for topic: {topic}\", show_header=True, header_style=\"bold magenta\"\n        )\n        table.add_column(\"Title\", style=\"dim\")\n        table.add_column(\"Published At\", style=\"dim\")\n        table.add_column(\"URL\", style=\"dim\")\n        for article in articles:\n            table.add_row(article.title, article.publishedAt, article.url)\n        console.print(table)\n\n        print(\"[bold orange_red1][INFO] Generating csv... [/bold orange_red1]\")\n        generate_csv_from_news_response(response, f\"{topic}.csv\")\n\n        print(\"[bold orange_red1][INFO] Generating summary... [/bold orange_red1]\")\n        headlines = [article.title for article in articles]\n        summary = nlp.summarize_headlines(headlines)\n        print(summary)\n\n        print(\"[bold orange_red1][INFO] Curating named entities... [/bold orange_red1]\")\n        named_entities = nlp.get_named_entities(headlines)\n        print(named_entities)\n</code></pre>"},{"location":"reference/lazy_search/cli/#lazy_search.cli.validate_langauge_input","title":"<code>validate_langauge_input(language: str) -&gt; str</code>","text":"Source code in <code>src/lazy_search/cli.py</code> <pre><code>def validate_langauge_input(language: str) -&gt; str:\n    if language not in ArticleLanguage.__members__.values():\n        raise UnsupportedLanguageException(language)\n    return language\n</code></pre>"},{"location":"reference/lazy_search/models/","title":"models","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.LanguageModels","title":"<code>LanguageModels = {ArticleLanguage.GERMAN: 'de_core_news_sm', ArticleLanguage.ENGLISH: 'en_core_web_sm', ArticleLanguage.SPANISH: 'es_core_news_sm', ArticleLanguage.FRENCH: 'fr_core_news_sm', ArticleLanguage.ITALIAN: 'it_core_news_sm', ArticleLanguage.DUTCH: 'nl_core_news_sm', ArticleLanguage.NORWEGIAN: 'nb_core_news_sm', ArticleLanguage.PORTUGUESE: 'pt_core_news_sm', ArticleLanguage.RUSSIAN: 'ru_core_news_sm', ArticleLanguage.SWEDISH: 'sv_core_news_sm'}</code>  <code>module-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage","title":"<code>ArticleLanguage</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/lazy_search/models.py</code> <pre><code>class ArticleLanguage(str, Enum):\n    GERMAN = \"de\"\n    ENGLISH = \"en\"\n    SPANISH = \"es\"\n    FRENCH = \"fr\"\n    ITALIAN = \"it\"\n    DUTCH = \"nl\"\n    NORWEGIAN = \"no\"\n    PORTUGUESE = \"pt\"\n    RUSSIAN = \"ru\"\n    SWEDISH = \"se\"\n</code></pre>"},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.DUTCH","title":"<code>DUTCH = 'nl'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.ENGLISH","title":"<code>ENGLISH = 'en'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.FRENCH","title":"<code>FRENCH = 'fr'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.GERMAN","title":"<code>GERMAN = 'de'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.ITALIAN","title":"<code>ITALIAN = 'it'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.NORWEGIAN","title":"<code>NORWEGIAN = 'no'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.PORTUGUESE","title":"<code>PORTUGUESE = 'pt'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.RUSSIAN","title":"<code>RUSSIAN = 'ru'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.SPANISH","title":"<code>SPANISH = 'es'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleLanguage.SWEDISH","title":"<code>SWEDISH = 'se'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleModel","title":"<code>ArticleModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/lazy_search/models.py</code> <pre><code>class ArticleModel(BaseModel):\n    title: str\n    url: str\n    publishedAt: str  # noqa: N815\n</code></pre>"},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleModel.publishedAt","title":"<code>publishedAt: str</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleModel.title","title":"<code>title: str</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.ArticleModel.url","title":"<code>url: str</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsRequestModel","title":"<code>NewsRequestModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/lazy_search/models.py</code> <pre><code>class NewsRequestModel(BaseModel):\n    q: str\n    language: str = \"en\"\n    sort_by: str = \"relevancy\"\n    page_size: int = 15\n</code></pre>"},{"location":"reference/lazy_search/models/#lazy_search.models.NewsRequestModel.language","title":"<code>language: str = 'en'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsRequestModel.page_size","title":"<code>page_size: int = 15</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsRequestModel.q","title":"<code>q: str</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsRequestModel.sort_by","title":"<code>sort_by: str = 'relevancy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsResponseModel","title":"<code>NewsResponseModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/lazy_search/models.py</code> <pre><code>class NewsResponseModel(BaseModel):\n    status: str\n    totalResults: int  # noqa: N815\n    articles: list[ArticleModel]\n</code></pre>"},{"location":"reference/lazy_search/models/#lazy_search.models.NewsResponseModel.articles","title":"<code>articles: list[ArticleModel]</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsResponseModel.status","title":"<code>status: str</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/models/#lazy_search.models.NewsResponseModel.totalResults","title":"<code>totalResults: int</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/news_fetcher/","title":"news_fetcher","text":""},{"location":"reference/lazy_search/news_fetcher/#lazy_search.news_fetcher.NewsFetcher","title":"<code>NewsFetcher</code>","text":"Source code in <code>src/lazy_search/news_fetcher.py</code> <pre><code>class NewsFetcher:\n    def __init__(self, api_key: str | None = \"\") -&gt; None:\n        if api_key == \"\":\n            api_key = os.environ.get(\"NEWS_API_KEY\")\n        self.news_api = NewsApiClient(api_key=api_key)\n\n    def search(\n        self, topic: str, language: ArticleLanguage = ArticleLanguage.ENGLISH\n    ) -&gt; NewsResponseModel:\n        request_model = NewsRequestModel(q=topic, language=language)\n        response = self.news_api.get_everything(**dict(request_model))\n        return NewsResponseModel(**response)\n</code></pre>"},{"location":"reference/lazy_search/news_fetcher/#lazy_search.news_fetcher.NewsFetcher.news_api","title":"<code>news_api = NewsApiClient(api_key=api_key)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/news_fetcher/#lazy_search.news_fetcher.NewsFetcher.__init__","title":"<code>__init__(api_key: str | None = '') -&gt; None</code>","text":"Source code in <code>src/lazy_search/news_fetcher.py</code> <pre><code>def __init__(self, api_key: str | None = \"\") -&gt; None:\n    if api_key == \"\":\n        api_key = os.environ.get(\"NEWS_API_KEY\")\n    self.news_api = NewsApiClient(api_key=api_key)\n</code></pre>"},{"location":"reference/lazy_search/news_fetcher/#lazy_search.news_fetcher.NewsFetcher.search","title":"<code>search(topic: str, language: ArticleLanguage = ArticleLanguage.ENGLISH) -&gt; NewsResponseModel</code>","text":"Source code in <code>src/lazy_search/news_fetcher.py</code> <pre><code>def search(\n    self, topic: str, language: ArticleLanguage = ArticleLanguage.ENGLISH\n) -&gt; NewsResponseModel:\n    request_model = NewsRequestModel(q=topic, language=language)\n    response = self.news_api.get_everything(**dict(request_model))\n    return NewsResponseModel(**response)\n</code></pre>"},{"location":"reference/lazy_search/nlp/","title":"nlp","text":""},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor","title":"<code>NaturalLanguageProcessor</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>class NaturalLanguageProcessor:\n    def __init__(self, language: ArticleLanguage = ArticleLanguage.ENGLISH) -&gt; None:\n        self.nlp_loader = NlpLoader()\n        self.nlp: Language = Language()\n        self.change_language(language)\n\n    def change_language(self, language: ArticleLanguage) -&gt; None:\n        self.nlp = self.nlp_loader.load_model(language=language)\n\n    def summarize_text(self, text: str) -&gt; str:\n        doc = self.nlp(text)\n        freq_of_word: dict[str, int] = {}\n\n        for token_word in doc:\n            if (\n                token_word.text.lower() not in list(self.nlp.Defaults.stop_words)\n                and token_word.text.lower() not in punctuation\n            ):\n                if token_word.text not in freq_of_word:\n                    freq_of_word[token_word.text] = 1\n                else:\n                    freq_of_word[token_word.text] += 1\n\n        max_freq = max(freq_of_word.values())\n        normalized_freq_of_word: dict[str, float] = {}\n        for word in freq_of_word:\n            normalized_freq_of_word[word] = freq_of_word[word] / max_freq\n\n        sent_tokens = list(doc.sents)\n        sent_scores = {}\n        for sent in sent_tokens:\n            for token_word in sent:\n                if token_word.text.lower() in normalized_freq_of_word:\n                    if sent not in sent_scores:\n                        sent_scores[sent] = normalized_freq_of_word[token_word.text.lower()]\n                    else:\n                        sent_scores[sent] += normalized_freq_of_word[token_word.text.lower()]\n\n        len_tokens = int(len(sent_tokens) * 0.2)\n\n        summary = nlargest(n=len_tokens, iterable=sent_scores, key=sent_scores.get)  # type: ignore\n\n        final_summary = [word.text for word in summary]\n\n        summary_str = \" \".join(final_summary)\n\n        return summary_str\n\n    @staticmethod\n    def format_headlines(headlines: list[str]) -&gt; str:\n        formatted_headlines = []\n        for headline in headlines:\n            if headline[-1] not in punctuation:\n                new_headline = headline + \".\"\n                formatted_headlines.append(new_headline)\n            else:\n                formatted_headlines.append(headline)\n\n        text = \" \".join(formatted_headlines)\n        return text\n\n    def summarize_headlines(self, headlines: list[str]) -&gt; str:\n        text = self.format_headlines(headlines)\n        summary = self.summarize_text(text)\n        return summary\n\n    def get_named_entities(self, headlines: list[str]) -&gt; dict[str, int]:\n        text = self.format_headlines(headlines)\n        return self.count_entities(text)\n\n    def count_entities(self, text: str) -&gt; dict[str, int]:\n        doc = self.nlp(text)\n        named_entities = [ent.text for ent in doc.ents]\n        entity_frequency = Counter(named_entities)\n        sorted_entities = sorted(entity_frequency.items(), key=lambda x: x[1], reverse=True)\n        return dict(sorted_entities)\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.nlp","title":"<code>nlp: Language = Language()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.nlp_loader","title":"<code>nlp_loader = NlpLoader()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.__init__","title":"<code>__init__(language: ArticleLanguage = ArticleLanguage.ENGLISH) -&gt; None</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def __init__(self, language: ArticleLanguage = ArticleLanguage.ENGLISH) -&gt; None:\n    self.nlp_loader = NlpLoader()\n    self.nlp: Language = Language()\n    self.change_language(language)\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.change_language","title":"<code>change_language(language: ArticleLanguage) -&gt; None</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def change_language(self, language: ArticleLanguage) -&gt; None:\n    self.nlp = self.nlp_loader.load_model(language=language)\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.count_entities","title":"<code>count_entities(text: str) -&gt; dict[str, int]</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def count_entities(self, text: str) -&gt; dict[str, int]:\n    doc = self.nlp(text)\n    named_entities = [ent.text for ent in doc.ents]\n    entity_frequency = Counter(named_entities)\n    sorted_entities = sorted(entity_frequency.items(), key=lambda x: x[1], reverse=True)\n    return dict(sorted_entities)\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.format_headlines","title":"<code>format_headlines(headlines: list[str]) -&gt; str</code>  <code>staticmethod</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>@staticmethod\ndef format_headlines(headlines: list[str]) -&gt; str:\n    formatted_headlines = []\n    for headline in headlines:\n        if headline[-1] not in punctuation:\n            new_headline = headline + \".\"\n            formatted_headlines.append(new_headline)\n        else:\n            formatted_headlines.append(headline)\n\n    text = \" \".join(formatted_headlines)\n    return text\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.get_named_entities","title":"<code>get_named_entities(headlines: list[str]) -&gt; dict[str, int]</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def get_named_entities(self, headlines: list[str]) -&gt; dict[str, int]:\n    text = self.format_headlines(headlines)\n    return self.count_entities(text)\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.summarize_headlines","title":"<code>summarize_headlines(headlines: list[str]) -&gt; str</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def summarize_headlines(self, headlines: list[str]) -&gt; str:\n    text = self.format_headlines(headlines)\n    summary = self.summarize_text(text)\n    return summary\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NaturalLanguageProcessor.summarize_text","title":"<code>summarize_text(text: str) -&gt; str</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def summarize_text(self, text: str) -&gt; str:\n    doc = self.nlp(text)\n    freq_of_word: dict[str, int] = {}\n\n    for token_word in doc:\n        if (\n            token_word.text.lower() not in list(self.nlp.Defaults.stop_words)\n            and token_word.text.lower() not in punctuation\n        ):\n            if token_word.text not in freq_of_word:\n                freq_of_word[token_word.text] = 1\n            else:\n                freq_of_word[token_word.text] += 1\n\n    max_freq = max(freq_of_word.values())\n    normalized_freq_of_word: dict[str, float] = {}\n    for word in freq_of_word:\n        normalized_freq_of_word[word] = freq_of_word[word] / max_freq\n\n    sent_tokens = list(doc.sents)\n    sent_scores = {}\n    for sent in sent_tokens:\n        for token_word in sent:\n            if token_word.text.lower() in normalized_freq_of_word:\n                if sent not in sent_scores:\n                    sent_scores[sent] = normalized_freq_of_word[token_word.text.lower()]\n                else:\n                    sent_scores[sent] += normalized_freq_of_word[token_word.text.lower()]\n\n    len_tokens = int(len(sent_tokens) * 0.2)\n\n    summary = nlargest(n=len_tokens, iterable=sent_scores, key=sent_scores.get)  # type: ignore\n\n    final_summary = [word.text for word in summary]\n\n    summary_str = \" \".join(final_summary)\n\n    return summary_str\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NlpLoader","title":"<code>NlpLoader</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>class NlpLoader:\n    @staticmethod\n    def get_model_name(language: ArticleLanguage) -&gt; str:\n        return LanguageModels[language]\n\n    def is_language_downloaded(self, language: ArticleLanguage) -&gt; bool:\n        model_name = self.get_model_name(language)\n        return model_name in spacy.util.get_installed_models()\n\n    def load_model(self, language: ArticleLanguage) -&gt; Language:\n        model_name = self.get_model_name(language)\n        try:\n            model_module = importlib.import_module(model_name)\n        except ModuleNotFoundError:\n            download(model_name)\n            model_module = importlib.import_module(model_name)\n        nlp: Language = model_module.load()\n        return nlp\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NlpLoader.get_model_name","title":"<code>get_model_name(language: ArticleLanguage) -&gt; str</code>  <code>staticmethod</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>@staticmethod\ndef get_model_name(language: ArticleLanguage) -&gt; str:\n    return LanguageModels[language]\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NlpLoader.is_language_downloaded","title":"<code>is_language_downloaded(language: ArticleLanguage) -&gt; bool</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def is_language_downloaded(self, language: ArticleLanguage) -&gt; bool:\n    model_name = self.get_model_name(language)\n    return model_name in spacy.util.get_installed_models()\n</code></pre>"},{"location":"reference/lazy_search/nlp/#lazy_search.nlp.NlpLoader.load_model","title":"<code>load_model(language: ArticleLanguage) -&gt; Language</code>","text":"Source code in <code>src/lazy_search/nlp.py</code> <pre><code>def load_model(self, language: ArticleLanguage) -&gt; Language:\n    model_name = self.get_model_name(language)\n    try:\n        model_module = importlib.import_module(model_name)\n    except ModuleNotFoundError:\n        download(model_name)\n        model_module = importlib.import_module(model_name)\n    nlp: Language = model_module.load()\n    return nlp\n</code></pre>"},{"location":"reference/lazy_search/utils/","title":"utils","text":""},{"location":"reference/lazy_search/utils/#lazy_search.utils.generate_csv","title":"<code>generate_csv(data: list[dict[str, str]], filename: str) -&gt; None</code>","text":"Source code in <code>src/lazy_search/utils.py</code> <pre><code>def generate_csv(data: list[dict[str, str]], filename: str) -&gt; None:\n    with Path(filename).open(\"w\", newline=\"\") as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=data[0].keys())\n        writer.writeheader()\n        for row in data:\n            writer.writerow(row)\n</code></pre>"},{"location":"reference/lazy_search/utils/#lazy_search.utils.generate_csv_from_news_response","title":"<code>generate_csv_from_news_response(news_response: NewsResponseModel, filename: str) -&gt; None</code>","text":"Source code in <code>src/lazy_search/utils.py</code> <pre><code>def generate_csv_from_news_response(news_response: NewsResponseModel, filename: str) -&gt; None:\n    articles = news_response.articles\n    articles_data = [dict(article) for article in articles]\n    generate_csv(articles_data, filename)\n</code></pre>"}]}